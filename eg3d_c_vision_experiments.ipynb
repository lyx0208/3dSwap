{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"10tpI22Lq2EHE7jCKN-fKoaEAhU-1tChY","authorship_tag":"ABX9TyPFnHtZXrzVVSd/z48Q4K3k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["DATASET PREPROCESSING NOTEBOOK USING EG3D BY PHILLIP T. CHANANDA\n","\n","CREDIT: NVIDIA LAB'S EG3D REPOSITORY\n","LINK: https://github.com/NVlabs/eg3d\n","PAPER: Efficient Geometry-aware {3D} Generative Adversarial Networks\n","AUTHORS: Eric R. Chan and Connor Z. Lin and Matthew A. Chan and Koki Nagano and Boxiao Pan and Shalini De Mello and Orazio Gallo and Leonidas Guibas and Jonathan Tremblay and Sameh Khamis and Tero Karras and Gordon Wetzstein\n","\n"],"metadata":{"id":"f210pMbSwbPH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvc3IQsdmKCz"},"outputs":[],"source":["# MOUNT YOUR GOOGLE DRIVE\n","# from google.colab import drive\n","# drive.mount(\"/content/drive/\")"]},{"cell_type":"code","source":["# GIT CLONE THE REPOSITORY"],"metadata":{"id":"TgbUXFwC1weA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/\"\n","!ls"],"metadata":{"id":"6VIP0kEOveFa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/NVlabs/eg3d.git\n","%cd eg3d"],"metadata":{"id":"jG-LTHQMCt5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# INSTALL CONDA\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install()"],"metadata":{"id":"HeZY2rjaI-nK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!conda --version"],"metadata":{"id":"1izhpsNjKQOm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/eg3d/eg3d\n","!ls"],"metadata":{"id":"aUbYeZ29EvE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mamba env update -f environment.yml"],"metadata":{"id":"-cwViFQnGhQN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","source activate eg3d"],"metadata":{"id":"I8062a7-K2T_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# INSTALL DEPENDENCIES\n","!pip install numpy kornia dominate tensorflow tensorboard scipy opencv-python scikit-image ninja trimesh\n","!pip install mtcnn\n","# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu119\n","!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu121"],"metadata":{"id":"e-UxPRRVMMOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# INSTALL NVIDIFFRAST\n","%cd /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch/nvdiffrast\n","!pip install ."],"metadata":{"id":"FXzcMIuzL6d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch"],"metadata":{"id":"0CN6yyMiTaKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq"],"metadata":{"id":"wWe3RVQlIdXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# INITIALIZE PATHS\n","# change to name of your dataset\n","dataset_name = \"all\"\n","dataset_path = \"/content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch/datasets/\"+dataset_name\n","print(dataset_path)"],"metadata":{"id":"rLhZt6WPPSCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RUN MTCNN NEEDED FOR Deep3DFaceRecon\n","!python batch_mtcnn.py --in_root {dataset_path}"],"metadata":{"id":"mIPJmpTEOnDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install --upgrade torch torchvision"],"metadata":{"id":"u9ZedzPDFLjD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch\n","!python test.py --img_folder={dataset_path} --gpu_ids=0 --name=pretrained --epoch=20"],"metadata":{"id":"ErqRv8ALLzw5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CROP THE IMAGES\n","%cd /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq\n","!python crop_images_in_the_wild.py --indir={dataset_path}"],"metadata":{"id":"MFKLh05NYWDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CONVERT POSE TO NEW FORMAT\n","%cd /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/\n","!python 3dface2idr_mat.py --in_root /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch/checkpoints/pretrained/results/{dataset_name}/epoch_20_000000 --out_path /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch/datasets/{dataset_name}/crop/cameras.json"],"metadata":{"id":"tuhy0RLkYdj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PREPROCESS FACE CAMERAS\n","!python preprocess_face_cameras.py --source /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch/datasets/{dataset_name}/crop --dest /content/drive/MyDrive/eg3d/dataset_preprocessing/ffhq/Deep3DFaceRecon_pytorch/datasets/{dataset_name}/preprocessed_cameras --mode orig"],"metadata":{"id":"DfkMdXF3ei_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CONCATENATE CAMERA_POSE\n","cameras_path = dataset_path+ \"/crop/cameras.json\"\n","print(cameras_path)\n","!python concate_camera_poses.py --cameras_path={cameras_path} --save_to={dataset_path}"],"metadata":{"id":"92t2dPh9dKrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MAKING SURE THE CAMERA_POSE FILES CORRESPONDS TO THE FINAL_CROPS FILES\n","import os\n","import cv2\n","import numpy as np\n","# SET YOUR DESIRED FINAL DATASET PATH\n","destination_folder = \"/content/drive/MyDrive/3dSwap/datasets/\"\n","cameras = dataset_path+\"/camera_pose/\"\n","crops = dataset_path+\"/crop/\"\n","final_crops = \"final_crops\"\n","camera_poses = \"camera_pose\"\n","\n","# CHECK IF CAMERA_POSE HAVE MATCHING FINAL_CROPS\n","for camera in os.listdir(cameras):\n","    new_camera = camera[:-4]\n","    for crop in os.listdir(crops):\n","        new_crop = crop[:-4]\n","        new_path = destination_folder + dataset_name + \"/\"\n","        if os.path.exists(new_path)==False:\n","            os.mkdir(new_path)\n","        if new_camera == new_crop:\n","            image = cv2.imread(crops+crop)\n","            camera_npy_file = np.load(cameras+camera)\n","            if os.path.exists(new_path+final_crops) or os.path.exists(new_path+camera_poses):\n","                print(\"Path --- \"+new_path+final_crops+\"/\"+crop)\n","                cv2.imwrite(new_path+final_crops+\"/\"+crop, image)\n","                np.save(new_path+camera_poses+\"/\"+camera, camera_npy_file)\n","            else:\n","                print(\"Path --- \"+new_path+final_crops+\"/\"+crop)\n","                os.mkdir(new_path+final_crops)\n","                os.makedirs(new_path+camera_poses)\n","                cv2.imwrite(new_path+final_crops+\"/\"+crop, image)\n","                np.save(new_path+camera_poses+\"/\"+camera, camera_npy_file)"],"metadata":{"id":"CQlC0a_8-q59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install click\n","# %cd /content/drive/MyDrive/eg3d/eg3d\n","# !python dataset_tool.py --source {dataset_path} --dest {dataset_path}"],"metadata":{"id":"iKNmoeA4RqIn"},"execution_count":null,"outputs":[]}]}